{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import requests\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib.ticker import MaxNLocator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z2cWmysNGCCz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tigva\\AppData\\Local\\Temp\\ipykernel_11728\\1453922826.py:34: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  new_df = pd.read_html(str(table), header=0)[0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Função para atualizar o DataFrame com novos dados\n",
        "def update_dataframe(df, new_data):\n",
        "    # Converte a coluna 'Data' para datetime\n",
        "    df['Data'] = pd.to_datetime(df['Data'], dayfirst=True)\n",
        "    new_data['Data'] = pd.to_datetime(new_data['Data'], dayfirst=True)\n",
        "\n",
        "    # Encontra a data mais recente no DataFrame existente\n",
        "    last_date = df['Data'].max()\n",
        "\n",
        "    # Filtra as novas linhas que são mais recentes do que a última data\n",
        "    new_rows = new_data[new_data['Data'] > last_date]\n",
        "\n",
        "    # Concatena os novos dados com o DataFrame existente se houver novas linhas\n",
        "    if not new_rows.empty:\n",
        "        updated_df = pd.concat([df, new_rows], ignore_index=True)\n",
        "    else:\n",
        "        updated_df = df\n",
        "\n",
        "    return updated_df\n",
        "\n",
        "# URL do site IPEADATA\n",
        "url = 'http://www.ipeadata.gov.br/ExibeSerie.aspx?module=m&serid=1650971490&oper=view'\n",
        "\n",
        "# Faz uma requisição GET ao site e captura a resposta\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem sucedida\n",
        "if response.status_code == 200:\n",
        "    # Cria um objeto BeautifulSoup para analisar o HTML\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    # Procura pela tabela no HTML analisado\n",
        "    table = soup.find('table', {'id': 'grd_DXMainTable'})\n",
        "    # Usa o pandas para ler a tabela HTML diretamente para um DataFrame\n",
        "    new_df = pd.read_html(str(table), header=0)[0]\n",
        "\n",
        "    # Verifica se o arquivo do DataFrame existe e carrega, ou cria um novo DataFrame se não existir\n",
        "    path = 'content/ipea.csv'\n",
        "    try:\n",
        "        existing_df = pd.read_csv(path)\n",
        "    except FileNotFoundError:\n",
        "        existing_df = new_df  # Se o arquivo não existir, considere os dados atuais como o DataFrame existente\n",
        "\n",
        "    # Atualiza o DataFrame existente com novos dados (carga incremental)\n",
        "    updated_df = update_dataframe(existing_df, new_df)\n",
        "\n",
        "    updated_df['Preço - petróleo bruto - Brent (FOB)'] = updated_df['Preço - petróleo bruto - Brent (FOB)']/100\n",
        "\n",
        "    # Salva o DataFrame atualizado para o arquivo\n",
        "    updated_df.to_csv(path, index=False)\n",
        "\n",
        "    # Mostra as primeiras linhas do DataFrame atualizado\n",
        "    updated_df.head()\n",
        "else:\n",
        "    print('Falha ao acessar a página: Status Code', response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "O1RwUAdFUsqC",
        "outputId": "551c1838-5320-46db-8121-0676fc9faf4c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Carregar o DataFrame\n",
        "df = pd.read_csv('content/ipea.csv')\n",
        "df['Data'] = pd.to_datetime(df['Data'])\n",
        "df = df.sort_values(by='Data', ascending=True).reset_index(drop=True)\n",
        "#df['Data'] = pd.to_datetime(df['Data'], dayfirst=True)\n",
        "#df['Preço'] = df['Preço'].astype(float)  # Certifique-se de que os preços são float\n",
        "\n",
        "# É uma boa prática criar recursos de atraso (lag features) para séries temporais\n",
        "# Vamos criar alguns para nosso modelo\n",
        "# Criar recursos de atraso (lag features)\n",
        "lags = 7\n",
        "for lag in range(1, lags + 1):\n",
        "    df[f'Preço_lag_{lag}'] = df['Preço - petróleo bruto - Brent (FOB)'].shift(lag)\n",
        "\n",
        "# Removemos quaisquer linhas com valores NaN que foram criados ao fazer o shift\n",
        "df = df.dropna()\n",
        "\n",
        "# Preparando os dados para treinamento\n",
        "X = df[['Preço_lag_1','Preço_lag_2','Preço_lag_3','Preço_lag_4','Preço_lag_5','Preço_lag_6','Preço_lag_7' ]].values  # Inputs são os preços atrasados\n",
        "y = df['Preço - petróleo bruto - Brent (FOB)'].values  # Output é o preço atual\n",
        "\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
        "\n",
        "# Criar e treinar o modelo de Gradient Boosting\n",
        "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, loss='squared_error')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "x_base = pd.DataFrame(X, columns = [ 'Preço_lag_1',\n",
        "       'Preço_lag_2', 'Preço_lag_3', 'Preço_lag_4', 'Preço_lag_5',\n",
        "       'Preço_lag_6', 'Preço_lag_7'])\n",
        "\n",
        "with open ('modelo_brent.pkl','wb') as file:\n",
        "    joblib.dump(model,file)\n",
        "\n",
        "x_base.to_csv('lag_features.csv')\n",
        "np.savetxt(\"y_test.txt\", y_test)\n",
        "np.savetxt(\"prediction.txt\", predictions)\n",
        "np.savetxt(\"X.txt\", X)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
